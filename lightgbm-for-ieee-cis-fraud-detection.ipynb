{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":13969004,"sourceType":"datasetVersion","datasetId":8905112}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport joblib\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport os\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-09T07:12:19.068760Z","iopub.execute_input":"2025-12-09T07:12:19.068991Z","iopub.status.idle":"2025-12-09T07:12:30.279963Z","shell.execute_reply.started":"2025-12-09T07:12:19.068969Z","shell.execute_reply":"2025-12-09T07:12:30.278965Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# !pip install --upgrade scikit-learn==1.7.2\n# import sklearn\n# print(sklearn.__version__)\n# !pip install --upgrade lightgbm\nprint(lgb.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T02:59:27.521953Z","iopub.execute_input":"2025-12-03T02:59:27.522326Z","iopub.status.idle":"2025-12-03T02:59:27.527718Z","shell.execute_reply.started":"2025-12-03T02:59:27.522298Z","shell.execute_reply":"2025-12-03T02:59:27.526624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(\"Loading data...\")\n\n# Auto-detect Kaggle environment\nif os.path.exists(\"/kaggle/input\"):\n    TRAIN_TRANS = \"/kaggle/input/ieee-fraud-detection/train_transaction.csv\"\n    TRAIN_IDENT = \"/kaggle/input/ieee-fraud-detection/train_identity.csv\"\nelse:\n    TRAIN_TRANS = \"train_transaction.csv\"\n    TRAIN_IDENT = \"train_identity.csv\"\n\ntrain_tr = pd.read_csv(TRAIN_TRANS, index_col=\"TransactionID\")\ntrain_id = pd.read_csv(TRAIN_IDENT, index_col=\"TransactionID\")\n\ntrain = train_tr.merge(train_id, how=\"left\", left_index=True, right_index=True)\n\n# target\ny = train[\"isFraud\"]\nX = train.drop(\"isFraud\", axis=1)\n\n# ---------------------------\n#  Feature list\n# ---------------------------\nnew_features = [\n            \"TransactionID\",\n            \"TransactionAmt\",\n            \"DeviceInfo\",\n            \"TransactionDT\",\n            \"ProductCD\",\n            \"card1\",\n            \"card2\",\n            \"card3\",\n            \"card4\",\n            \"card5\",\n            \"card6\",\n            \"addr1\",\n            \"addr2\",\n            \"dist1\",\n            \"dist2\",\n            \"P_emaildomain\",\n            \"R_emaildomain\",\n        ]\n# Filter only available columns\nfeatures = [f for f in new_features if f in X.columns]\nX = X[features]\n\n# ---------------------------\n# Fill NA\n# ---------------------------\nX = X.fillna(-999)\n\n# ---------------------------\n# Label Encoding\n# ---------------------------\nlabel_encoders = {}\n\nfor col in X.columns:\n    if X[col].dtype == \"object\":\n        le = LabelEncoder()\n        X[col] = le.fit_transform(X[col].astype(str))\n        label_encoders[col] = le\n\njoblib.dump(label_encoders, \"label_encoders.pkl\")\njoblib.dump(features, \"model_features.pkl\")\n\n# ---------------------------\n# Train/Val Split\n# ---------------------------\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# ---------------------------\n# LightGBM Model\n# ---------------------------\ntrain_ds = lgb.Dataset(X_train, label=y_train)\nval_ds = lgb.Dataset(X_val, label=y_val)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T07:13:07.093136Z","iopub.execute_input":"2025-12-09T07:13:07.093447Z","iopub.status.idle":"2025-12-09T07:13:37.710786Z","shell.execute_reply.started":"2025-12-09T07:13:07.093424Z","shell.execute_reply":"2025-12-09T07:13:37.709967Z"}},"outputs":[{"name":"stdout","text":"Loading data...\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\nparams = {\n    \"objective\": \"binary\",\n    \"metric\": \"auc\",\n    \"boosting_type\": \"gbdt\",\n    \"learning_rate\": 0.03,\n    \"num_leaves\": 128,\n    \"max_depth\": -1,\n    \"feature_fraction\": 0.8,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 3,\n    \"verbosity\": -1,\n}\n\nmodel = lgb.train(\n    params,\n    train_ds,\n    valid_sets=[train_ds, val_ds],\n    num_boost_round=4000,\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=300),\n        lgb.log_evaluation(period=200)\n    ]\n)\n\n\nmodel.save_model(\"ieee_lgbm.txt\")\n# Evaluate Validation AUC\nval_pred = model.predict(X_val)\nauc = roc_auc_score(y_val, val_pred)\nprint(\"Validation AUC:\", auc)\nprint(\"MODEL TRAINED AND SAVED SUCCESSFULLY!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T07:22:32.692935Z","iopub.execute_input":"2025-12-09T07:22:32.693927Z","iopub.status.idle":"2025-12-09T07:29:04.387339Z","shell.execute_reply.started":"2025-12-09T07:22:32.693893Z","shell.execute_reply":"2025-12-09T07:29:04.386160Z"}},"outputs":[{"name":"stdout","text":"Training until validation scores don't improve for 300 rounds\n[200]\ttraining's auc: 0.94068\tvalid_1's auc: 0.913912\n[400]\ttraining's auc: 0.966935\tvalid_1's auc: 0.931471\n[600]\ttraining's auc: 0.980516\tvalid_1's auc: 0.941028\n[800]\ttraining's auc: 0.987849\tvalid_1's auc: 0.945804\n[1000]\ttraining's auc: 0.992008\tvalid_1's auc: 0.949551\n[1200]\ttraining's auc: 0.995008\tvalid_1's auc: 0.952272\n[1400]\ttraining's auc: 0.996736\tvalid_1's auc: 0.954013\n[1600]\ttraining's auc: 0.997865\tvalid_1's auc: 0.955349\n[1800]\ttraining's auc: 0.9986\tvalid_1's auc: 0.956509\n[2000]\ttraining's auc: 0.99907\tvalid_1's auc: 0.9572\n[2200]\ttraining's auc: 0.999396\tvalid_1's auc: 0.957837\n[2400]\ttraining's auc: 0.999603\tvalid_1's auc: 0.958292\n[2600]\ttraining's auc: 0.999749\tvalid_1's auc: 0.958649\n[2800]\ttraining's auc: 0.999835\tvalid_1's auc: 0.958938\n[3000]\ttraining's auc: 0.999892\tvalid_1's auc: 0.959222\n[3200]\ttraining's auc: 0.99993\tvalid_1's auc: 0.959506\n[3400]\ttraining's auc: 0.999957\tvalid_1's auc: 0.959692\n[3600]\ttraining's auc: 0.999974\tvalid_1's auc: 0.959906\n[3800]\ttraining's auc: 0.999983\tvalid_1's auc: 0.960058\n[4000]\ttraining's auc: 0.99999\tvalid_1's auc: 0.960176\nDid not meet early stopping. Best iteration is:\n[3996]\ttraining's auc: 0.99999\tvalid_1's auc: 0.960177\nValidation AUC: 0.9601774263093422\nMODEL TRAINED AND SAVED SUCCESSFULLY!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/786179626.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MODEL TRAINED AND SAVED SUCCESSFULLY!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tree_info\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tree_structure\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_depth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Tree {i}: depth = {depth}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'max_depth'"],"ename":"KeyError","evalue":"'max_depth'","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"def get_tree_depth(tree_structure):\n    if \"left_child\" not in tree_structure and \"right_child\" not in tree_structure:\n        return 1\n\n    left_depth = right_depth = 0\n\n    if \"left_child\" in tree_structure:\n        left_depth = get_tree_depth(tree_structure[\"left_child\"])\n    if \"right_child\" in tree_structure:\n        right_depth = get_tree_depth(tree_structure[\"right_child\"])\n\n    return 1 + max(left_depth, right_depth)\n\n\n# Collect depths\nmodel_json = model.dump_model()\ntree_depths = []\n\nfor tree in model_json[\"tree_info\"]:\n    depth = get_tree_depth(tree[\"tree_structure\"])\n    tree_depths.append(depth)\n\n# Statistics\nmax_depth = max(tree_depths)\nmin_depth = min(tree_depths)\navg_depth = sum(tree_depths) / len(tree_depths)\n\nprint(\"\\n--- Depth Summary ---\")\nprint(f\"Max depth: {max_depth}\")\nprint(f\"Min depth: {min_depth}\")\nprint(f\"Average depth: {avg_depth:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T07:42:19.532713Z","iopub.execute_input":"2025-12-09T07:42:19.533045Z","iopub.status.idle":"2025-12-09T07:42:35.209828Z","shell.execute_reply.started":"2025-12-09T07:42:19.533021Z","shell.execute_reply":"2025-12-09T07:42:35.209009Z"}},"outputs":[{"name":"stdout","text":"\n--- Depth Summary ---\nMax depth: 41\nMin depth: 13\nAverage depth: 20.97\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Auto-detect Kaggle\nif os.path.exists(\"/kaggle/input\"):\n    TEST_TRANS = \"/kaggle/input/ieee-fraud-detection/test_transaction.csv\"\n    TEST_IDENT = \"/kaggle/input/ieee-fraud-detection/test_identity.csv\"\nelse:\n    TEST_TRANS = \"test_transaction.csv\"\n    TEST_IDENT = \"test_identity.csv\"\n\n# Load test data\ntest_tr = pd.read_csv(TEST_TRANS, index_col=\"TransactionID\")\ntest_id = pd.read_csv(TEST_IDENT, index_col=\"TransactionID\")\ntest = test_tr.merge(test_id, how=\"left\", left_index=True, right_index=True)\n\nMODEL_PATH = \"/kaggle/working/ieee_lgbm.txt\"\nFEATURES_PATH = \"/kaggle/working/model_features.pkl\"\nENCODERS_PATH = \"/kaggle/working/label_encoders.pkl\"\n\nmodel = lgb.Booster(model_file=MODEL_PATH)\nfeatures = joblib.load(FEATURES_PATH)\nlabel_encoders = joblib.load(ENCODERS_PATH)\n\n\n# -----------------------------\n# Choose only a subset of features for testing\n# -----------------------------\nselected_features = [\n            \"TransactionID\",\n            \"TransactionAmt\",\n            \"DeviceInfo\",\n            \"TransactionDT\",\n            \"ProductCD\",\n            \"card1\",\n            \"card2\",\n            \"card3\",\n            \"card4\",\n            \"card5\",\n            \"card6\",\n            \"addr1\",\n            \"addr2\",\n            \"dist1\",\n            \"dist2\",\n            \"P_emaildomain\",\n            \"R_emaildomain\",\n        ]\n\n# Keep only features that exist in test\nexisting_features = [f for f in selected_features if f in test.columns]\nX_test = test[existing_features].copy()\n\n# -----------------------------\n# Preprocess categorical features\n# -----------------------------\nfor col in X_test.columns:\n    if col in label_encoders:\n        le = label_encoders[col]\n        # Replace unseen labels with a placeholder\n        X_test[col] = X_test[col].astype(str).map(lambda x: x if x in le.classes_ else \"unseen_before_label\")\n        # Refit the encoder to include the placeholder if missing\n        if \"unseen_before_label\" not in le.classes_:\n            le_classes = list(le.classes_) + [\"unseen_before_label\"]\n            le.classes_ = np.array(le_classes)\n        X_test[col] = le.transform(X_test[col])\n\n# -----------------------------\n# Fill missing numeric features with -999\n# -----------------------------\nfor col in X_test.columns:\n    if col not in label_encoders:  # numeric\n        X_test[col] = X_test[col].fillna(-999)\n\n# -----------------------------\n# Make predictions\n# -----------------------------\npreds = model.predict(X_test)\nauc = roc_auc_score(y_val, preds)\n# submission = pd.DataFrame({\n#     \"TransactionID\": X_test.index,\n#     \"isFraud\": preds\n# })\n\n# submission.to_csv(\"submission.csv\", index=False)\n# print(\"Saved submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T05:17:23.972606Z","iopub.execute_input":"2025-12-03T05:17:23.973150Z","iopub.status.idle":"2025-12-03T05:20:19.955903Z","shell.execute_reply.started":"2025-12-03T05:17:23.973119Z","shell.execute_reply":"2025-12-03T05:20:19.954469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport lightgbm as lgb\nimport joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nprint(\"Loading data...\")\n\n# Auto-detect Kaggle environment\nif os.path.exists(\"/kaggle/input\"):\n    TRAIN_TRANS = \"/kaggle/input/ieee-fraud-detection/train_transaction.csv\"\n    TRAIN_IDENT = \"/kaggle/input/ieee-fraud-detection/train_identity.csv\"\nelse:\n    TRAIN_TRANS = \"train_transaction.csv\"\n    TRAIN_IDENT = \"train_identity.csv\"\n\ntrain_tr = pd.read_csv(TRAIN_TRANS, index_col=\"TransactionID\")\ntrain_id = pd.read_csv(TRAIN_IDENT, index_col=\"TransactionID\")\n\ntrain = train_tr.merge(train_id, how=\"left\", left_index=True, right_index=True)\n\n# target\ny = train[\"isFraud\"]\nX = train.drop(\"isFraud\", axis=1)\n\n# ---------------------------\n#  Feature list\n# ---------------------------\nnew_features = [\n    \"TransactionID\", \"TransactionAmt\", \"DeviceInfo\", \"TransactionDT\",\n    \"ProductCD\", \"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\",\n    \"addr1\", \"addr2\", \"dist1\", \"dist2\", \"P_emaildomain\", \"R_emaildomain\"\n]\nfeatures = [f for f in new_features if f in X.columns]\nX = X[features]\n\n# ---------------------------\n# Fill NA\n# ---------------------------\nX = X.fillna(-999)\n\n# ---------------------------\n# Label Encoding\n# ---------------------------\nlabel_encoders = {}\nfor col in X.columns:\n    if X[col].dtype == \"object\":\n        le = LabelEncoder()\n        X[col] = le.fit_transform(X[col].astype(str))\n        label_encoders[col] = le\n\njoblib.dump(label_encoders, \"label_encoders.pkl\")\njoblib.dump(features, \"model_features.pkl\")\n\n# ---------------------------\n# Train/Val Split\n# ---------------------------\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# ---------------------------\n# LightGBM Model\n# ---------------------------\ntrain_ds = lgb.Dataset(X_train, label=y_train)\nval_ds = lgb.Dataset(X_val, label=y_val)\n\nevals_result = {}  # dictionary to store evaluation results\n\nparams = {\n    \"objective\": \"binary\",\n    \"metric\": [\"auc\", \"binary_logloss\"],\n    \"boosting_type\": \"gbdt\",\n    \"learning_rate\": 0.03,\n    \"num_leaves\": 128,\n    \"max_depth\": -1,\n    \"feature_fraction\": 0.8,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 3,\n    \"verbosity\": -1,\n}\n\nmodel = lgb.train(\n    params,\n    train_ds,\n    valid_sets=[train_ds, val_ds],\n    valid_names=[\"train\", \"valid\"],\n    num_boost_round=3000,\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=200),\n        lgb.log_evaluation(period=200),\n        lgb.record_evaluation(evals_result)  # <-- store metrics here\n    ]\n)\n\nmodel.save_model(\"ieee_lgbm.txt\")\njoblib.dump(evals_result, \"evals_result.pkl\")\n\n# ---------------------------\n# Evaluate Validation AUC\n# ---------------------------\nval_pred = model.predict(X_val)\nauc = roc_auc_score(y_val, val_pred)\nprint(\"Validation AUC:\", auc)\n\n# ============================================================\n# 1. TRAINING vs VALIDATION AUC CURVE\n# ============================================================\nplt.figure(figsize=(10, 5))\nplt.plot(evals_result[\"train\"][\"auc\"], label=\"Train AUC\")\nplt.plot(evals_result[\"valid\"][\"auc\"], label=\"Validation AUC\")\nplt.title(\"AUC Curve\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"AUC\")\nplt.legend()\nplt.grid(True)\nplt.savefig(\"curve_auc.png\", dpi=300)\nplt.show()\n\n# ============================================================\n# 2. TRAINING vs VALIDATION LOGLOSS CURVE\n# ============================================================\nplt.figure(figsize=(10, 5))\nplt.plot(evals_result[\"train\"][\"binary_logloss\"], label=\"Train Logloss\")\nplt.plot(evals_result[\"valid\"][\"binary_logloss\"], label=\"Valid Logloss\")\nplt.title(\"Logloss Curve\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Logloss\")\nplt.legend()\nplt.grid(True)\nplt.savefig(\"curve_logloss.png\", dpi=300)\nplt.show()\n\n# ============================================================\n# 3. FEATURE IMPORTANCE\n# ============================================================\nimportance = model.feature_importance(importance_type=\"gain\")\nindices = np.argsort(importance)[::-1]\nfeat_names_sorted = X.columns[indices]\n\nplt.figure(figsize=(10, 7))\nplt.barh(feat_names_sorted, importance[indices])\nplt.title(\"Feature Importance (Gain)\")\nplt.xlabel(\"Importance\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.savefig(\"feature_importance.png\", dpi=300)\nplt.show()\n\n# ============================================================\n# 4. PRECISIONâ€“RECALL CURVE\n# ============================================================\nprecision, recall, thresholds = precision_recall_curve(y_val, val_pred)\nap = average_precision_score(y_val, val_pred)\n\nplt.figure(figsize=(10, 5))\nplt.plot(recall, precision)\nplt.title(f\"Precision-Recall Curve (AP = {ap:.4f})\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.grid(True)\nplt.savefig(\"precision_recall.png\", dpi=300)\nplt.show()\n\nprint(\"ALL PLOTS SAVED!\")\nprint(\" - curve_auc.png\")\nprint(\" - curve_logloss.png\")\nprint(\" - feature_importance.png\")\nprint(\" - precision_recall.png\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T10:04:06.081123Z","iopub.execute_input":"2025-12-08T10:04:06.081525Z","iopub.status.idle":"2025-12-08T10:09:01.375010Z","shell.execute_reply.started":"2025-12-08T10:04:06.081489Z","shell.execute_reply":"2025-12-08T10:09:01.374197Z"}},"outputs":[],"execution_count":null}]}